{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T18:56:00.757953Z",
     "start_time": "2019-10-07T18:55:57.435821Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we call 'test' the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T18:56:00.768800Z",
     "start_time": "2019-10-07T18:56:00.763667Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# get data PATH from current directory\n",
    "PATH = os.path.join(Path(os.getcwd()).parent, 'data')\n",
    "\n",
    "\n",
    "PATH_DATASET = os.path.join(PATH, 'datasets')\n",
    "\n",
    "PATH_VOCAB = os.path.join(PATH, 'vocabularies')\n",
    "\n",
    "PATH_MODEL = os.path.join(PATH, 'models')\n",
    "\n",
    "PATH_STATS = os.path.join(PATH, 'stats')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-07T18:59:31.915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and test set in pandas dataframe\n",
    "\n",
    "train = pd.read_hdf(os.path.join(PATH_DATASET,'train_set.h5'))\n",
    "test = pd.read_hdf(os.path.join(PATH_DATASET,'test_set.h5'))\n",
    "\n",
    "train_rel = pd.read_hdf(os.path.join(PATH_DATASET,'train_set_rel.h5'))\n",
    "train_unrel = pd.read_hdf(os.path.join(PATH_DATASET,'train_set_unrel.h5'))\n",
    "\n",
    "# Load vocabulary\n",
    "\n",
    "file = open(os.path.join(PATH_VOCAB,'vocab_0.0015.pkl'), 'rb')\n",
    "vocab = pickle.load(file)\n",
    "\n",
    "\n",
    "# Load classes dictionary\n",
    "\n",
    "file = open(os.path.join(PATH,'classes_dict.pkl'), 'rb')\n",
    "classes_dict = pickle.load(file)\n",
    "\n",
    "cat_dict = classes_dict['class_stoi']\n",
    "cat_dict_inv = classes_dict['class_itos']\n",
    "dict_count = classes_dict['class_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize\n",
    "\n",
    "Make BoW using my tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-07T18:59:34.414Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "# Define the vectorizer to generate the BoW\n",
    "\n",
    "vectorizer_tok = CountVectorizer(\n",
    "                             analyzer = 'word',\n",
    "                             strip_accents='unicode',\n",
    "                             vocabulary=vocab\n",
    "                            )\n",
    "\n",
    "\n",
    "# Reset indexes of the training set before vectorizer\n",
    "train = train.reset_index()\n",
    "\n",
    "# Vectorize the training and test_set\n",
    "vectors_train = vectorizer_tok.fit_transform(train.title)\n",
    "\n",
    "vectors_test = vectorizer_tok.transform(test.title)\n",
    "\n",
    "\n",
    "y_train = train.category.values\n",
    "\n",
    "X_test = vectors_test\n",
    "y_test = test.category.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-07T18:59:35.201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split training set by categories\n",
    "list_train_rel = list(train_rel.groupby('category'))\n",
    "list_train_unrel = list(train_unrel.groupby('category'))\n",
    "\n",
    "class_rel = train_rel.groupby('category').count().title.index\n",
    "class_unrel = train_unrel.groupby('category').count().title.index\n",
    "\n",
    "\n",
    "file = open(os.path.join(PATH,'classes_weights.pkl'), 'rb')\n",
    "weights = pickle.load(file)\n",
    "\n",
    "\n",
    "def numero(weight, num_examples, proporcion):\n",
    "    \n",
    "    if weight==0:\n",
    "        return 0\n",
    "        \n",
    "    return int(min(max(1, round(num_examples*weight*proporcion)), num_examples-1))\n",
    "\n",
    "\n",
    "def index_sample(list_train_rel, list_train_unrel, num_samples, proporcion):\n",
    "    list_idx = []\n",
    "    \n",
    "    # Unreliable indexes\n",
    "    \n",
    "    for i in range(len(class_unrel)):\n",
    "        # Convention index\n",
    "        idx = cat_dict[class_unrel[i]]\n",
    "        number = num_samples - numero(weights[idx,2], num_samples, proporcion)\n",
    "        list_idx += list(np.random.choice(list_train_unrel[i][1].index, size=number))\n",
    "    \n",
    "    # Reliable indexes\n",
    "    for i,category in enumerate(class_rel):\n",
    "        \n",
    "        idx = cat_dict[class_rel[i]]\n",
    "        number = numero(weights[idx,2], num_samples, proporcion)\n",
    "        list_idx += list(np.random.choice(list_train_rel[i][1].index, size=number))\n",
    "    \n",
    "    \n",
    "    return list_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions in CPU\n",
    "\n",
    "Functions to calculate bacc and accuracy using CPU.\n",
    "\n",
    "We train the model using GPU, but we don't have enough memory to run the predictions in the validation set while training. So that, at the end of each epoch we set the model to the cpu, make predictions in the validation set and then set the model to gpu and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-07T18:59:35.957Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from numpy import array\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "\n",
    "\n",
    "def report(model, X_test, y_test):\n",
    "    \n",
    "    x_tensor = csr_to_tensor(X_test)\n",
    "    model_cpu = model.to('cpu')\n",
    "    outputs = model_cpu(x_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted.cpu().numpy()\n",
    "    y_label = []\n",
    "    for val in y_test:\n",
    "        y_label.append(cat_dict[val])\n",
    "    y_label = np.array(y_label)\n",
    "    \n",
    "    return balanced_accuracy_score(y_label, predicted), accuracy_score(y_label, predicted)\n",
    "\n",
    "\n",
    "def csr_to_tensor(X_sample):\n",
    "    coo = coo_matrix(X_sample)\n",
    "\n",
    "    values = coo.data\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    shape = coo.shape\n",
    "\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "def numerate(y):\n",
    "    index = []\n",
    "    for i in y:\n",
    "        index.append(cat_dict[i])\n",
    "    return np.array(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-07T18:59:36.624Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_size = vectors_train.shape[1]\n",
    "num_classes = len(train.category.unique())\n",
    "H = num_classes\n",
    "\n",
    "H1 = 2*num_classes\n",
    "\n",
    "vec_prop = [10]\n",
    "vec_num_epochs = [35] \n",
    "vec_learning_rate = [0.0005]\n",
    "\n",
    "\n",
    "for learning_rate, num_epochs, prop in zip(vec_learning_rate, vec_num_epochs, vec_prop):\n",
    "\n",
    "    ## Define model\n",
    "    model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(input_size, H1),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Dropout(p=0.75),\n",
    "          torch.nn.Linear(H1, num_classes),\n",
    "    ).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Some training stats\n",
    "    model_stats = {}\n",
    "    model_stats['epoch'] = []\n",
    "    model_stats['avg_loss'] = []\n",
    "    model_stats['accuracy'] = []\n",
    "    model_stats['bacc'] = []\n",
    "\n",
    "    # Record maximum BACC value\n",
    "    max_bacc = 0\n",
    "    num_max = 0\n",
    "    \n",
    "    \n",
    "    # Epochs aren't 'real epochs' in which we use all the training set. \n",
    "    # Instead each epochs is a collection of 1000 mini-batches generated using the sampling defined above\n",
    "    # Each epoch only defines when and how many times we evaluate the model using the validation set.\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        list_loss = []\n",
    "        \n",
    "        for i in range(1000):\n",
    "            \n",
    "            # List of index of the minibatch using the function defined above\n",
    "            list_idx = index_sample(list_train_rel, list_train_unrel, 10, prop)\n",
    "            \n",
    "            X = vectors_train[list_idx, :]\n",
    "            y = y_train[list_idx]\n",
    "            \n",
    "            X_sample, y_sample = shuffle(X, y)\n",
    "\n",
    "            x_tensor = csr_to_tensor(X_sample).to(device)\n",
    "\n",
    "            labels = torch.from_numpy(numerate(y_sample)).long().to(device)\n",
    "\n",
    "            outputs = model(x_tensor)\n",
    "            #images.to('cpu')\n",
    "            #torch.cuda.empty_cache()\n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            lo = loss.item()\n",
    "            list_loss.append(lo)\n",
    "            # Test\n",
    "            #outputs.to('cpu')\n",
    "            #torch.cuda.empty_cache()\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, lo )) ##ss.item()))\n",
    "\n",
    "        ## Statistics\n",
    "\n",
    "        # Bacc and accuracy\n",
    "        \n",
    "        bacc, accuracy = report(model.eval(), X_test, y_test)\n",
    "        print(bacc,accuracy)\n",
    "        model.to(device)\n",
    "\n",
    "        # Save in the model_stats dictionary\n",
    "        model_stats['epoch'].append(epoch)\n",
    "        model_stats['bacc'].append(bacc)\n",
    "        model_stats['accuracy'].append(accuracy)\n",
    "        model_stats['avg_loss'].append(np.array(list_loss).mean())\n",
    "        \n",
    "\n",
    "        if bacc > max_bacc:\n",
    "            max_bacc = bacc\n",
    "            torch.save(model, os.path.join(PATH_MODEL,'model_00015_prop{}_lr{}.pt'.format(learning_rate)))\n",
    "\n",
    "\n",
    "        with open( os.path.join(PATH_STATS,'stats_00015_prop{}_lr{}.pt'.format(learning_rate)), 'wb') as f:\n",
    "            pickle.dump(model_stats, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
